{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "hw4XJDRwNngE"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "\n",
        "# GPU & Memory Setup\n",
        "\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cuda.matmul.allow_tf32 = False\n",
        "torch.backends.cudnn.allow_tf32 = False\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# 2️⃣ Data Augmentation & Loading\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(224, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                         (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                         (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# ✅ Dataset definitions\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform_test)\n",
        "\n",
        "# ✅ Reduced batch size to prevent OOM\n",
        "trainloader = DataLoader(trainset, batch_size=16, shuffle=True, num_workers=2)\n",
        "testloader  = DataLoader(testset, batch_size=16, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "# 3️⃣ Load Pretrained ResNet50 (Fine-Tuning)\n",
        "\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Freeze early layers, train last residual block + classifier\n",
        "for name, param in model.named_parameters():\n",
        "    if \"layer4\" in name or \"fc\" in name:\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "\n",
        "# Replace final FC layer for CIFAR-10\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.4),\n",
        "    nn.Linear(256, 10)\n",
        ")\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "# 4️⃣ Loss, Optimizer & Scheduler\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "\n",
        "# 5️⃣ Training Loop (with Mixed Precision)\n",
        "\n",
        "epochs = 15\n",
        "scaler = torch.cuda.amp.GradScaler()  # mixed precision scaler\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in trainloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Mixed precision context\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    scheduler.step()\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}] Loss: {running_loss/len(trainloader):.4f}\")\n",
        "\n",
        "\n",
        "# 6️⃣ Evaluation\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"✅ Test Accuracy: {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-nNvvDOO7ce",
        "outputId": "0aa04b3f-c1f5-46ad-e21f-7498a5503d9d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/tmp/ipython-input-2816154120.py:89: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()  # mixed precision scaler\n",
            "/tmp/ipython-input-2816154120.py:101: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/15] Loss: 0.5016\n",
            "Epoch [2/15] Loss: 0.3041\n",
            "Epoch [3/15] Loss: 0.2351\n",
            "Epoch [4/15] Loss: 0.1912\n",
            "Epoch [5/15] Loss: 0.1634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2816154120.py:101: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/15] Loss: 0.0900\n",
            "Epoch [7/15] Loss: 0.0671\n",
            "Epoch [8/15] Loss: 0.0590\n",
            "Epoch [9/15] Loss: 0.0503\n",
            "Epoch [10/15] Loss: 0.0459\n",
            "Epoch [11/15] Loss: 0.0394\n",
            "Epoch [12/15] Loss: 0.0384\n",
            "Epoch [13/15] Loss: 0.0384\n",
            "Epoch [14/15] Loss: 0.0372\n",
            "Epoch [15/15] Loss: 0.0357\n",
            "✅ Test Accuracy: 94.97%\n"
          ]
        }
      ]
    }
  ]
}